from book_translator.discovery import find_series_root, load_series_config
from book_translator.db import get_terms, get_all_chapters, get_chunks
from pathlib import Path


def run_status(args):
    series_root = find_series_root()
    config = load_series_config(series_root)
    glossary_db = series_root / 'glossary.db'

    print(f"üìö –°–µ—Ä–∏—è: {config['series']['name']}")
    print(f"   –Ø–∑—ã–∫–∏: {config['series']['source_lang']} ‚Üí {config['series']['target_lang']}")
    print(f"   –ú–æ–¥–µ–ª—å: {config['gemini_cli']['model']}")
    print(f"   –ö–æ—Ä–µ–Ω—å: {series_root}")

    # Count glossary terms
    terms = get_terms(glossary_db,
                     config['series']['source_lang'],
                     config['series']['target_lang'])
    print(f"   –ì–ª–æ—Å—Å–∞—Ä–∏–π: {len(terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤")

    # List volumes and their status
    print("\nüìñ –¢–æ–º–∞:")
    for item in sorted(series_root.iterdir()):
        if item.is_dir() and (item / 'source').is_dir():
            chunks_db = item / '.state' / 'chunks.db'
            if chunks_db.is_file():
                chapters = get_all_chapters(chunks_db)
                total_chunks = sum(len(get_chunks(chunks_db, ch)) for ch in chapters)
                print(f"   {item.name}: {len(chapters)} –≥–ª–∞–≤, {total_chunks} —á–∞–Ω–∫–æ–≤")
            else:
                source_files = list((item / 'source').glob('*.txt'))
                print(f"   {item.name}: {len(source_files)} —Ñ–∞–π–ª–æ–≤ (–Ω–µ –Ω–∞—á–∞—Ç)")
